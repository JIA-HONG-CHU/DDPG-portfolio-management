{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/workspace/200g/DDPG-portfolio-management/weights/stock/lstm/window_6\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Jun 17 10:13:34 2020       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 430.30       Driver Version: 430.30       CUDA Version: 10.2     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  GRID V100D-4Q       On   | 00000000:02:02.0 Off |                    0 |\n",
      "| N/A   N/A    P0    N/A /  N/A |   1611MiB /  4078MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                       GPU Memory |\n",
      "|  GPU       PID   Type   Process name                             Usage      |\n",
      "|=============================================================================|\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tflearn/helpers/summarizer.py:9: The name tf.summary.merge is deprecated. Please use tf.compat.v1.summary.merge instead.\n",
      "\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tflearn/helpers/trainer.py:25: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.\n",
      "\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tflearn/collections.py:13: The name tf.GraphKeys is deprecated. Please use tf.compat.v1.GraphKeys instead.\n",
      "\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tflearn/config.py:123: The name tf.get_collection is deprecated. Please use tf.compat.v1.get_collection instead.\n",
      "\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tflearn/config.py:129: The name tf.add_to_collection is deprecated. Please use tf.compat.v1.add_to_collection instead.\n",
      "\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tflearn/config.py:131: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
      "\n",
      "{'batch_norm': 'True',\n",
      " 'batch_size': 10,\n",
      " 'debug': False,\n",
      " 'predictor_type': 'lstm',\n",
      " 'rollout_steps': 2,\n",
      " 'training_end': '20161101',\n",
      " 'training_start': '20050301',\n",
      " 'window_length': '4'}\n",
      "/opt/conda/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "WARNING:tensorflow:From stock_trading.py:315: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
      "\n",
      "WARNING:tensorflow:From stock_trading.py:316: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "2020-06-17 10:14:32.728027: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
      "2020-06-17 10:14:32.767695: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2020-06-17 10:14:32.768296: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n",
      "name: GRID V100D-4Q major: 7 minor: 0 memoryClockRate(GHz): 1.38\n",
      "pciBusID: 0000:02:02.0\n",
      "2020-06-17 10:14:32.768637: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcudart.so.10.0'; dlerror: libcudart.so.10.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/compat/lib:/usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
      "2020-06-17 10:14:32.768798: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcublas.so.10.0'; dlerror: libcublas.so.10.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/compat/lib:/usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
      "2020-06-17 10:14:32.768935: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcufft.so.10.0'; dlerror: libcufft.so.10.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/compat/lib:/usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
      "2020-06-17 10:14:32.769071: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcurand.so.10.0'; dlerror: libcurand.so.10.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/compat/lib:/usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
      "2020-06-17 10:14:32.769201: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcusolver.so.10.0'; dlerror: libcusolver.so.10.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/compat/lib:/usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
      "2020-06-17 10:14:32.769328: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcusparse.so.10.0'; dlerror: libcusparse.so.10.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/compat/lib:/usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
      "2020-06-17 10:14:33.390289: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
      "2020-06-17 10:14:33.390351: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1641] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2020-06-17 10:14:33.390810: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA\n",
      "2020-06-17 10:14:33.468153: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2294605000 Hz\n",
      "2020-06-17 10:14:33.471551: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55c21d920e60 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-06-17 10:14:33.471632: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "2020-06-17 10:14:33.709566: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2020-06-17 10:14:33.710215: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55c21bbde420 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2020-06-17 10:14:33.710250: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): GRID V100D-4Q, Compute Capability 7.0\n",
      "2020-06-17 10:14:33.710347: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2020-06-17 10:14:33.710361: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      \n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tflearn/layers/core.py:81: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tflearn/layers/recurrent.py:69: static_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `keras.layers.RNN(cell, unroll=True)`, which is equivalent to this API\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tflearn/layers/recurrent.py:553: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n",
      "\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tflearn/initializations.py:174: calling TruncatedNormal.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tflearn/initializations.py:75: calling RandomUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From /workspace/200g/DDPG-portfolio-management/model/ddpg/actor.py:47: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.\n",
      "\n",
      "WARNING:tensorflow:From /workspace/200g/DDPG-portfolio-management/model/ddpg/actor.py:68: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\n",
      "WARNING:tensorflow:From /workspace/200g/DDPG-portfolio-management/model/ddpg/actor.py:71: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /workspace/200g/DDPG-portfolio-management/model/ddpg/ddpg.py:19: The name tf.summary.scalar is deprecated. Please use tf.compat.v1.summary.scalar instead.\n",
      "\n",
      "WARNING:tensorflow:From /workspace/200g/DDPG-portfolio-management/model/ddpg/ddpg.py:24: The name tf.summary.merge_all is deprecated. Please use tf.compat.v1.summary.merge_all instead.\n",
      "\n",
      "WARNING:tensorflow:From /workspace/200g/DDPG-portfolio-management/model/ddpg/ddpg.py:60: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "WARNING:tensorflow:From /workspace/200g/DDPG-portfolio-management/model/ddpg/ddpg.py:62: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/workspace/200g/DDPG-portfolio-management/model/ddpg/ddpg.py\", line 63, in initialize\n",
      "    saver.restore(self.sess, self.model_save_path)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/training/saver.py\", line 1280, in restore\n",
      "    if not checkpoint_management.checkpoint_exists_internal(checkpoint_prefix):\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/training/checkpoint_management.py\", line 366, in checkpoint_exists_internal\n",
      "    if file_io.get_matching_files(pathname):\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/lib/io/file_io.py\", line 363, in get_matching_files\n",
      "    return get_matching_files_v2(filename)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/lib/io/file_io.py\", line 384, in get_matching_files_v2\n",
      "    compat.as_bytes(pattern))\n",
      "tensorflow.python.framework.errors_impl.NotFoundError: weights/stock/lstm/window_4/batch_norm; No such file or directory\n",
      "Build model from scratch\n",
      "WARNING:tensorflow:From /workspace/200g/DDPG-portfolio-management/model/ddpg/ddpg.py:72: The name tf.global_variables_initializer is deprecated. Please use tf.compat.v1.global_variables_initializer instead.\n",
      "\n",
      "WARNING:tensorflow:Issue encountered when serializing data_preprocessing.\n",
      "Type is unsupported, or the types of the items don't match field type in CollectionDef. Note this is a warning and probably safe to ignore.\n",
      "'NoneType' object has no attribute 'name'\n",
      "WARNING:tensorflow:Issue encountered when serializing data_augmentation.\n",
      "Type is unsupported, or the types of the items don't match field type in CollectionDef. Note this is a warning and probably safe to ignore.\n",
      "'NoneType' object has no attribute 'name'\n",
      "10000\n",
      "Episode: 0, Reward: 0.99290, Qmax: 0.00000\n",
      "WARNING:tensorflow:Issue encountered when serializing data_preprocessing.\n",
      "Type is unsupported, or the types of the items don't match field type in CollectionDef. Note this is a warning and probably safe to ignore.\n",
      "'NoneType' object has no attribute 'name'\n",
      "WARNING:tensorflow:Issue encountered when serializing data_augmentation.\n",
      "Type is unsupported, or the types of the items don't match field type in CollectionDef. Note this is a warning and probably safe to ignore.\n",
      "'NoneType' object has no attribute 'name'\n",
      "Episode: 1, Reward: 0.99065, Qmax: 0.00199\n",
      "Episode: 2, Reward: 0.94127, Qmax: -0.00578\n",
      "Episode: 3, Reward: 0.96954, Qmax: 0.00408\n",
      "Episode: 4, Reward: 0.97302, Qmax: 0.00564\n",
      "Episode: 5, Reward: 1.06933, Qmax: 0.00478\n",
      "Episode: 6, Reward: 1.04463, Qmax: 0.00158\n",
      "Episode: 7, Reward: 0.99065, Qmax: -0.00016\n",
      "Episode: 8, Reward: 1.03329, Qmax: 0.00005\n",
      "Episode: 9, Reward: 0.98760, Qmax: 0.00096\n",
      "Episode: 10, Reward: 1.04721, Qmax: 0.00211\n",
      "Episode: 11, Reward: 0.96628, Qmax: 0.00314\n",
      "Episode: 12, Reward: 0.99939, Qmax: 0.00458\n",
      "Episode: 13, Reward: 1.01115, Qmax: 0.00434\n",
      "Episode: 14, Reward: 0.94127, Qmax: 0.00551\n",
      "Episode: 15, Reward: 0.98130, Qmax: 0.00565\n",
      "Episode: 16, Reward: 1.00724, Qmax: 0.00512\n",
      "Episode: 17, Reward: 0.98527, Qmax: 0.00506\n",
      "Episode: 18, Reward: 1.05331, Qmax: 0.00414\n",
      "Episode: 19, Reward: 1.07274, Qmax: 0.00387\n",
      "Episode: 20, Reward: 0.98028, Qmax: 0.00297\n",
      "Episode: 21, Reward: 0.96224, Qmax: 0.00222\n",
      "Episode: 22, Reward: 1.08377, Qmax: 0.00200\n",
      "Episode: 23, Reward: 0.99303, Qmax: 0.00155\n",
      "Episode: 24, Reward: 1.06933, Qmax: 0.00014\n",
      "Episode: 25, Reward: 0.89542, Qmax: -0.00118\n",
      "Episode: 26, Reward: 1.02788, Qmax: -0.00181\n",
      "Episode: 27, Reward: 0.92740, Qmax: -0.00232\n",
      "Episode: 28, Reward: 0.96224, Qmax: -0.00273\n",
      "Episode: 29, Reward: 0.99024, Qmax: -0.00292\n",
      "Episode: 30, Reward: 0.94127, Qmax: -0.00298\n",
      "Episode: 31, Reward: 0.96210, Qmax: -0.00278\n",
      "Episode: 32, Reward: 1.00902, Qmax: -0.00246\n",
      "Episode: 33, Reward: 0.97661, Qmax: -0.00223\n",
      "Episode: 34, Reward: 0.98130, Qmax: -0.00204\n",
      "Episode: 35, Reward: 0.99303, Qmax: -0.00155\n",
      "Episode: 36, Reward: 0.95809, Qmax: -0.00109\n",
      "Episode: 37, Reward: 0.95309, Qmax: -0.00019\n",
      "Episode: 38, Reward: 0.99142, Qmax: 0.00018\n",
      "Episode: 39, Reward: 0.96628, Qmax: 0.00086\n",
      "Episode: 40, Reward: 0.91967, Qmax: 0.00166\n",
      "Episode: 41, Reward: 1.02788, Qmax: 0.00211\n",
      "Episode: 42, Reward: 0.99170, Qmax: 0.00246\n",
      "Episode: 43, Reward: 1.00902, Qmax: 0.00261\n",
      "Episode: 44, Reward: 1.04463, Qmax: 0.00245\n",
      "Episode: 45, Reward: 0.99290, Qmax: 0.00264\n",
      "Episode: 46, Reward: 0.94271, Qmax: 0.00247\n",
      "Episode: 47, Reward: 1.02643, Qmax: 0.00217\n",
      "Episode: 48, Reward: 0.99024, Qmax: 0.00151\n",
      "Episode: 49, Reward: 0.95814, Qmax: 0.00078\n",
      "Episode: 50, Reward: 1.01647, Qmax: 0.00012\n",
      "Episode: 51, Reward: 0.95590, Qmax: -0.00030\n",
      "Episode: 52, Reward: 1.08787, Qmax: -0.00043\n",
      "Episode: 53, Reward: 0.97302, Qmax: -0.00052\n",
      "Episode: 54, Reward: 0.95814, Qmax: -0.00080\n",
      "Episode: 55, Reward: 0.89542, Qmax: -0.00101\n",
      "Episode: 56, Reward: 0.96210, Qmax: -0.00094\n",
      "Episode: 57, Reward: 1.01460, Qmax: -0.00092\n",
      "Episode: 58, Reward: 1.18981, Qmax: -0.00085\n",
      "Episode: 59, Reward: 0.96232, Qmax: -0.00098\n",
      "Episode: 60, Reward: 0.93320, Qmax: -0.00109\n",
      "Episode: 61, Reward: 0.98846, Qmax: -0.00102\n",
      "Episode: 62, Reward: 0.99966, Qmax: -0.00112\n",
      "Episode: 63, Reward: 0.94127, Qmax: -0.00088\n",
      "Episode: 64, Reward: 0.96628, Qmax: -0.00089\n",
      "Episode: 65, Reward: 0.94127, Qmax: -0.00083\n",
      "Episode: 66, Reward: 0.99224, Qmax: -0.00094\n",
      "Episode: 67, Reward: 0.92740, Qmax: -0.00114\n",
      "Episode: 68, Reward: 1.02998, Qmax: -0.00073\n",
      "Episode: 69, Reward: 0.92740, Qmax: -0.00044\n",
      "Episode: 70, Reward: 0.96224, Qmax: -0.00072\n",
      "Episode: 71, Reward: 0.95171, Qmax: -0.00117\n",
      "Episode: 72, Reward: 0.98130, Qmax: -0.00298\n",
      "Episode: 73, Reward: 0.97837, Qmax: -0.00347\n",
      "Episode: 74, Reward: 1.01647, Qmax: -0.00402\n",
      "Episode: 75, Reward: 0.97523, Qmax: -0.00435\n",
      "Episode: 76, Reward: 0.98527, Qmax: -0.00475\n",
      "Episode: 77, Reward: 1.18981, Qmax: -0.00463\n",
      "Episode: 78, Reward: 0.96781, Qmax: -0.00372\n",
      "Episode: 79, Reward: 0.97523, Qmax: -0.00212\n",
      "Episode: 80, Reward: 0.97370, Qmax: -0.00025\n",
      "Episode: 81, Reward: 0.94080, Qmax: 0.00057\n",
      "Episode: 82, Reward: 1.00120, Qmax: 0.00137\n",
      "Episode: 83, Reward: 0.97523, Qmax: 0.00174\n",
      "Episode: 84, Reward: 0.99966, Qmax: 0.00210\n",
      "Episode: 85, Reward: 0.97903, Qmax: 0.00191\n",
      "Episode: 86, Reward: 0.98580, Qmax: 0.00157\n",
      "Episode: 87, Reward: 0.96165, Qmax: 0.00100\n",
      "Episode: 88, Reward: 1.00013, Qmax: -0.00012\n",
      "Episode: 89, Reward: 0.99170, Qmax: 0.00011\n",
      "Episode: 90, Reward: 0.98130, Qmax: 0.00013\n",
      "Episode: 91, Reward: 1.01993, Qmax: 0.00012\n",
      "Episode: 92, Reward: 1.02098, Qmax: 0.00043\n",
      "Episode: 93, Reward: 1.02643, Qmax: 0.00053\n",
      "Episode: 94, Reward: 0.97837, Qmax: 0.00066\n",
      "Episode: 95, Reward: 0.95809, Qmax: 0.00106\n",
      "Episode: 96, Reward: 1.03329, Qmax: 0.00136\n",
      "Episode: 97, Reward: 0.92740, Qmax: 0.00160\n",
      "Episode: 98, Reward: 1.01647, Qmax: 0.00173\n",
      "Episode: 99, Reward: 1.10957, Qmax: 0.00151\n",
      "Episode: 100, Reward: 1.07274, Qmax: 0.00134\n",
      "WARNING:tensorflow:Issue encountered when serializing data_preprocessing.\n",
      "Type is unsupported, or the types of the items don't match field type in CollectionDef. Note this is a warning and probably safe to ignore.\n",
      "'NoneType' object has no attribute 'name'\n",
      "WARNING:tensorflow:Issue encountered when serializing data_augmentation.\n",
      "Type is unsupported, or the types of the items don't match field type in CollectionDef. Note this is a warning and probably safe to ignore.\n",
      "'NoneType' object has no attribute 'name'\n",
      "Episode: 101, Reward: 0.96224, Qmax: 0.00135\n",
      "Episode: 102, Reward: 0.95301, Qmax: 0.00156\n",
      "Episode: 103, Reward: 1.07621, Qmax: 0.00208\n",
      "Episode: 104, Reward: 0.92740, Qmax: 0.00236\n",
      "Episode: 105, Reward: 1.02262, Qmax: 0.00243\n",
      "Episode: 106, Reward: 1.07274, Qmax: 0.00242\n",
      "Episode: 107, Reward: 0.98527, Qmax: 0.00207\n",
      "Episode: 108, Reward: 0.99224, Qmax: 0.00188\n",
      "Episode: 109, Reward: 0.97523, Qmax: 0.00150\n",
      "Episode: 110, Reward: 1.00013, Qmax: 0.00132\n",
      "Episode: 111, Reward: 0.99579, Qmax: 0.00112\n",
      "Episode: 112, Reward: 0.97523, Qmax: 0.00065\n",
      "Episode: 113, Reward: 0.96232, Qmax: 0.00001\n",
      "Episode: 114, Reward: 0.86975, Qmax: -0.00015\n",
      "Episode: 115, Reward: 0.99939, Qmax: -0.00068\n",
      "Episode: 116, Reward: 0.92740, Qmax: -0.00076\n",
      "Episode: 117, Reward: 1.01506, Qmax: -0.00079\n",
      "Episode: 118, Reward: 0.98074, Qmax: -0.00104\n",
      "Episode: 119, Reward: 1.00538, Qmax: -0.00098\n",
      "Episode: 120, Reward: 0.98620, Qmax: -0.00087\n",
      "Episode: 121, Reward: 0.97854, Qmax: -0.00048\n",
      "Episode: 122, Reward: 1.05690, Qmax: -0.00062\n",
      "Episode: 123, Reward: 0.99142, Qmax: 0.00002\n",
      "Episode: 124, Reward: 1.06933, Qmax: 0.00070\n",
      "Episode: 125, Reward: 0.98837, Qmax: 0.00186\n",
      "Episode: 126, Reward: 1.02998, Qmax: 0.00270\n",
      "Episode: 127, Reward: 0.96224, Qmax: 0.00244\n",
      "Episode: 128, Reward: 0.95412, Qmax: 0.00312\n",
      "Episode: 129, Reward: 1.02643, Qmax: 0.00246\n",
      "Episode: 130, Reward: 0.98527, Qmax: 0.00320\n",
      "Episode: 131, Reward: 0.95309, Qmax: 0.00319\n",
      "Episode: 132, Reward: 1.10957, Qmax: 0.00215\n",
      "Episode: 133, Reward: 0.98130, Qmax: 0.00124\n",
      "Episode: 134, Reward: 0.96307, Qmax: 0.00099\n",
      "Episode: 135, Reward: 0.96232, Qmax: 0.00097\n",
      "Episode: 136, Reward: 1.02086, Qmax: 0.00091\n",
      "Episode: 137, Reward: 1.18981, Qmax: 0.00061\n",
      "Episode: 138, Reward: 0.98760, Qmax: 0.00105\n",
      "Episode: 139, Reward: 1.04721, Qmax: 0.00094\n",
      "Episode: 140, Reward: 0.98028, Qmax: 0.00112\n",
      "Episode: 141, Reward: 1.01647, Qmax: 0.00117\n",
      "Episode: 142, Reward: 0.96209, Qmax: 0.00114\n",
      "Episode: 143, Reward: 0.98074, Qmax: 0.00169\n",
      "Episode: 144, Reward: 0.94271, Qmax: 0.00224\n",
      "Episode: 145, Reward: 0.98527, Qmax: 0.00307\n",
      "Episode: 146, Reward: 0.98028, Qmax: 0.00357\n",
      "Episode: 147, Reward: 0.99040, Qmax: 0.00393\n",
      "Episode: 148, Reward: 0.97800, Qmax: 0.00430\n",
      "Episode: 149, Reward: 0.97537, Qmax: 0.00449\n",
      "Episode: 150, Reward: 0.97537, Qmax: 0.00446\n",
      "Episode: 151, Reward: 0.99579, Qmax: 0.00380\n",
      "Episode: 152, Reward: 1.01115, Qmax: 0.00389\n",
      "Episode: 153, Reward: 0.96232, Qmax: 0.00301\n",
      "Episode: 154, Reward: 1.02098, Qmax: 0.00242\n",
      "Episode: 155, Reward: 1.01506, Qmax: 0.00157\n",
      "Episode: 156, Reward: 0.92759, Qmax: 0.00102\n",
      "Episode: 157, Reward: 0.93911, Qmax: 0.00084\n",
      "Episode: 158, Reward: 1.01312, Qmax: 0.00052\n",
      "Episode: 159, Reward: 1.02643, Qmax: -0.00067\n",
      "Episode: 160, Reward: 0.98620, Qmax: -0.00040\n",
      "Episode: 161, Reward: 0.92740, Qmax: -0.00019\n",
      "Episode: 162, Reward: 0.98994, Qmax: -0.00020\n",
      "Episode: 163, Reward: 0.96809, Qmax: 0.00014\n",
      "Episode: 164, Reward: 0.99615, Qmax: 0.00047\n",
      "Episode: 165, Reward: 0.97250, Qmax: 0.00088\n",
      "Episode: 166, Reward: 0.98324, Qmax: 0.00072\n",
      "Episode: 167, Reward: 1.07171, Qmax: 0.00154\n",
      "Episode: 168, Reward: 0.95232, Qmax: 0.00102\n",
      "Episode: 169, Reward: 0.98994, Qmax: 0.00069\n",
      "Episode: 170, Reward: 0.97703, Qmax: 0.00041\n",
      "Episode: 171, Reward: 1.06491, Qmax: 0.00064\n",
      "Episode: 172, Reward: 0.93432, Qmax: 0.00006\n",
      "Episode: 173, Reward: 0.93883, Qmax: 0.00007\n",
      "Episode: 174, Reward: 1.01783, Qmax: 0.00034\n",
      "Episode: 175, Reward: 1.00902, Qmax: 0.00059\n",
      "Episode: 176, Reward: 1.08787, Qmax: 0.00149\n",
      "Episode: 177, Reward: 1.02788, Qmax: 0.00185\n",
      "Episode: 178, Reward: 1.05690, Qmax: 0.00277\n",
      "Episode: 179, Reward: 0.99142, Qmax: 0.00350\n",
      "Episode: 180, Reward: 0.96209, Qmax: 0.00254\n",
      "Episode: 181, Reward: 1.03329, Qmax: 0.00343\n",
      "Episode: 182, Reward: 0.96954, Qmax: 0.00298\n",
      "Episode: 183, Reward: 0.99627, Qmax: 0.00273\n",
      "Episode: 184, Reward: 1.07676, Qmax: 0.00230\n",
      "Episode: 185, Reward: 0.96736, Qmax: 0.00196\n",
      "Episode: 186, Reward: 1.00902, Qmax: 0.00133\n",
      "Episode: 187, Reward: 0.96379, Qmax: 0.00113\n",
      "Episode: 188, Reward: 0.99065, Qmax: 0.00110\n",
      "Episode: 189, Reward: 1.08377, Qmax: 0.00110\n",
      "Episode: 190, Reward: 0.97800, Qmax: 0.00111\n",
      "Episode: 191, Reward: 1.02998, Qmax: 0.00109\n",
      "Episode: 192, Reward: 0.98618, Qmax: 0.00121\n",
      "Episode: 193, Reward: 0.95590, Qmax: 0.00103\n",
      "Episode: 194, Reward: 0.97009, Qmax: 0.00080\n",
      "Episode: 195, Reward: 0.92740, Qmax: 0.00089\n",
      "Episode: 196, Reward: 1.03329, Qmax: 0.00033\n",
      "Episode: 197, Reward: 0.95301, Qmax: 0.00068\n",
      "Episode: 198, Reward: 0.98823, Qmax: 0.00041\n",
      "Episode: 199, Reward: 1.01173, Qmax: 0.00170\n",
      "Episode: 200, Reward: 0.94080, Qmax: 0.00328\n",
      "WARNING:tensorflow:Issue encountered when serializing data_preprocessing.\n",
      "Type is unsupported, or the types of the items don't match field type in CollectionDef. Note this is a warning and probably safe to ignore.\n",
      "'NoneType' object has no attribute 'name'\n",
      "WARNING:tensorflow:Issue encountered when serializing data_augmentation.\n",
      "Type is unsupported, or the types of the items don't match field type in CollectionDef. Note this is a warning and probably safe to ignore.\n",
      "'NoneType' object has no attribute 'name'\n",
      "Episode: 201, Reward: 0.98620, Qmax: 0.00201\n",
      "Episode: 202, Reward: 0.97903, Qmax: 0.00498\n",
      "Episode: 203, Reward: 1.01460, Qmax: 0.00517\n",
      "Episode: 204, Reward: 1.04463, Qmax: 0.00407\n",
      "Episode: 205, Reward: 0.98837, Qmax: 0.00966\n",
      "Episode: 206, Reward: 1.02098, Qmax: 0.01114\n",
      "Episode: 207, Reward: 0.99597, Qmax: 0.00943\n",
      "Episode: 208, Reward: 0.96165, Qmax: 0.00588\n",
      "Episode: 209, Reward: 1.09548, Qmax: 0.00881\n",
      "Episode: 210, Reward: 0.98527, Qmax: 0.00948\n",
      "Episode: 211, Reward: 0.97903, Qmax: 0.00640\n",
      "Episode: 212, Reward: 1.00724, Qmax: 0.00552\n",
      "Episode: 213, Reward: 0.95171, Qmax: 0.00458\n",
      "Episode: 214, Reward: 0.97703, Qmax: 0.00511\n",
      "Episode: 215, Reward: 1.07171, Qmax: 0.00385\n",
      "Episode: 216, Reward: 1.08377, Qmax: 0.00239\n",
      "Episode: 217, Reward: 0.99224, Qmax: 0.00179\n",
      "Episode: 218, Reward: 0.98846, Qmax: 0.00085\n",
      "Episode: 219, Reward: 0.99024, Qmax: 0.00159\n",
      "Episode: 220, Reward: 0.99303, Qmax: 0.00060\n",
      "Episode: 221, Reward: 1.03269, Qmax: 0.00271\n",
      "Episode: 222, Reward: 1.01173, Qmax: 0.00286\n",
      "Episode: 223, Reward: 1.05974, Qmax: 0.00406\n",
      "Episode: 224, Reward: 1.03329, Qmax: 0.00676\n",
      "Episode: 225, Reward: 0.94271, Qmax: 0.00500\n",
      "Episode: 226, Reward: 1.01647, Qmax: 0.00498\n",
      "Episode: 227, Reward: 0.94998, Qmax: 0.00687\n",
      "Episode: 228, Reward: 0.94127, Qmax: 0.00446\n",
      "Episode: 229, Reward: 0.99290, Qmax: 0.00780\n",
      "Episode: 230, Reward: 1.00013, Qmax: 0.00918\n",
      "Episode: 231, Reward: 1.05331, Qmax: 0.00848\n",
      "Episode: 232, Reward: 0.99653, Qmax: 0.01013\n",
      "Episode: 233, Reward: 1.05690, Qmax: 0.00986\n",
      "^C\n",
      "Traceback (most recent call last):\n",
      "  File \"stock_trading.py\", line 326, in <module>\n",
      "    ddpg_model.train()\n",
      "  File \"/workspace/200g/DDPG-portfolio-management/model/ddpg/ddpg.py\", line 146, in train\n",
      "    _, reward_p, _, _ = self.env.step(action_p, simulation=1)\n",
      "  File \"/workspace/200g/DDPG-portfolio-management/environment/portfolio.py\", line 258, in step\n",
      "    return self._step(action, simulation)\n",
      "  File \"/workspace/200g/DDPG-portfolio-management/environment/portfolio.py\", line 281, in _step\n",
      "    np.sum(weights), [1.0], 3, err_msg='weights should sum to 1. action=\"%s\"' % weights)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/numpy/core/arrayprint.py\", line 1529, in _array_str_implementation\n",
      "    return array2string(a, max_line_width, precision, suppress_small, ' ', \"\")\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/numpy/core/arrayprint.py\", line 700, in array2string\n",
      "    return _array2string(a, options, separator, prefix)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/numpy/core/arrayprint.py\", line 472, in wrapper\n",
      "    return f(self, *args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/numpy/core/arrayprint.py\", line 498, in _array2string\n",
      "    format_function = _get_format_function(data, **options)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/numpy/core/arrayprint.py\", line 431, in _get_format_function\n",
      "    return formatdict['float']()\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/numpy/core/arrayprint.py\", line 370, in <lambda>\n",
      "    FloatingFormat(data, prec, fmode, supp, sign, legacy=legacy),\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/numpy/core/arrayprint.py\", line 869, in __init__\n",
      "    self.fillFormat(data)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/numpy/core/arrayprint.py\", line 926, in fillFormat\n",
      "    int_part, frac_part = zip(*(s.split('.') for s in strs))\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/numpy/core/arrayprint.py\", line 926, in <genexpr>\n",
      "    int_part, frac_part = zip(*(s.split('.') for s in strs))\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "!python stock_trading.py -p lstm  -w 6 -b True -ts 20050301 -te 20161101"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
